{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f16e594-1ba8-4caf-8127-30d3a51c5790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -qqqU wandb datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7082c65b-dabb-4b77-9df8-c5687a78753c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WANDB_PROJECT = \"wandbot_llm\"\n",
    "\n",
    "RAW_TRAIN_DATASET_ARTIFACT = 'capecape/wandbot/run-m6nz6yrl-wandbot_questions:v0'\n",
    "RAW_EVAL_DATASET_ARTIFACT  = \"wandbot/wandbot-eval/run-kinbxic4-responses:v0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f2b7e0-dab7-46aa-b287-9721efb8dae3",
   "metadata": {},
   "source": [
    "# Preparing Data\n",
    "How to prepare our dataset for model Finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0a3457-8941-45d5-9ff8-eef4fa936a7b",
   "metadata": {},
   "source": [
    "## Formatting the data for the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ca2daa-0c44-4ac1-ba98-1d70f87fd3e8",
   "metadata": {},
   "source": [
    "A big part of training LLMs lives in getting the data formatted correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6df869f-739b-409d-a50a-495dad432777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d27c251-56b5-4f64-9268-ebc900720a7f",
   "metadata": {},
   "source": [
    "let's create a run and monitor our work from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d57c25c0-a7b0-4161-8207-f990785ddab9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install \"protobuf<4.24.4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d36272c4-55fb-4792-a422-3a64595c54ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcapecape\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/cape/wandbot_llm/wandb/run-20231018_121927-yrkl2cco</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/capecape/wandbot_llm/runs/yrkl2cco' target=\"_blank\">cosmic-plasma-7</a></strong> to <a href='https://wandb.ai/capecape/wandbot_llm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/capecape/wandbot_llm' target=\"_blank\">https://wandb.ai/capecape/wandbot_llm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/capecape/wandbot_llm/runs/yrkl2cco' target=\"_blank\">https://wandb.ai/capecape/wandbot_llm/runs/yrkl2cco</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/capecape/wandbot_llm/runs/yrkl2cco?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f449c0c2130>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=WANDB_PROJECT, job_type=\"text_formatting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03fe450f-a6bd-4da7-900f-479cb5902f07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "# this way we get tracebility\n",
    "dataset_artifact = wandb.use_artifact(RAW_TRAIN_DATASET_ARTIFACT, type='run_table')\n",
    "table = dataset_artifact.get(\"wandbot_questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f902fa8-1b3c-4f19-af81-94372c0a16f7",
   "metadata": {},
   "source": [
    "this is a W&B table, so we can convert it to whatever format we may need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "372833dc-d535-464e-936e-765731418b46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>page_content</th>\n",
       "      <th>metadata</th>\n",
       "      <th>context_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A user has just started using the Weights &amp; Bi...</td>\n",
       "      <td>What is a 'run' in W&amp;B and what can I use it for?</td>\n",
       "      <td>A 'run' in W&amp;B is the fundamental unit that yo...</td>\n",
       "      <td>import Tabs from â€˜@theme/Tabsâ€™;  \\n\\nimport Ta...</td>\n",
       "      <td>{'file_type': '.md', 'language': 'en', 'source...</td>\n",
       "      <td>1291.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A user has just started using W&amp;B and they are...</td>\n",
       "      <td>Hi! I'm new to W&amp;B and I'm a bit stuck. Can yo...</td>\n",
       "      <td>Sure, you can install the W&amp;B library on your ...</td>\n",
       "      <td>import Tabs from â€˜@theme/Tabsâ€™;  \\n\\nimport Ta...</td>\n",
       "      <td>{'file_type': '.md', 'language': 'en', 'source...</td>\n",
       "      <td>1291.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The user is getting started with Weights and B...</td>\n",
       "      <td>I need to track my experiment's hyperparameter...</td>\n",
       "      <td>Certainly! You can pass your hyperparameters t...</td>\n",
       "      <td>import Tabs from â€˜@theme/Tabsâ€™;  \\n\\nimport Ta...</td>\n",
       "      <td>{'file_type': '.md', 'language': 'en', 'source...</td>\n",
       "      <td>1291.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A user is trying to do some mathematical opera...</td>\n",
       "      <td>How do I multiply two numbers using W&amp;B functi...</td>\n",
       "      <td>To multiply two numbers, you can use the `numb...</td>\n",
       "      <td>Value\\n\\n\\nWhether the two values are not equ...</td>\n",
       "      <td>{'file_type': '.md', 'language': 'en', 'source...</td>\n",
       "      <td>2186.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A user has been working on making sense of a d...</td>\n",
       "      <td>Hi, I have some confusing numbers that represe...</td>\n",
       "      <td>Yes, there is a function in W&amp;B that allows yo...</td>\n",
       "      <td>Value\\n\\n\\nWhether the two values are not equ...</td>\n",
       "      <td>{'file_type': '.md', 'language': 'en', 'source...</td>\n",
       "      <td>2186.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  A user has just started using the Weights & Bi...   \n",
       "2  A user has just started using W&B and they are...   \n",
       "4  The user is getting started with Weights and B...   \n",
       "5  A user is trying to do some mathematical opera...   \n",
       "6  A user has been working on making sense of a d...   \n",
       "\n",
       "                                            question  \\\n",
       "0  What is a 'run' in W&B and what can I use it for?   \n",
       "2  Hi! I'm new to W&B and I'm a bit stuck. Can yo...   \n",
       "4  I need to track my experiment's hyperparameter...   \n",
       "5  How do I multiply two numbers using W&B functi...   \n",
       "6  Hi, I have some confusing numbers that represe...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  A 'run' in W&B is the fundamental unit that yo...   \n",
       "2  Sure, you can install the W&B library on your ...   \n",
       "4  Certainly! You can pass your hyperparameters t...   \n",
       "5  To multiply two numbers, you can use the `numb...   \n",
       "6  Yes, there is a function in W&B that allows yo...   \n",
       "\n",
       "                                        page_content  \\\n",
       "0  import Tabs from â€˜@theme/Tabsâ€™;  \\n\\nimport Ta...   \n",
       "2  import Tabs from â€˜@theme/Tabsâ€™;  \\n\\nimport Ta...   \n",
       "4  import Tabs from â€˜@theme/Tabsâ€™;  \\n\\nimport Ta...   \n",
       "5   Value\\n\\n\\nWhether the two values are not equ...   \n",
       "6   Value\\n\\n\\nWhether the two values are not equ...   \n",
       "\n",
       "                                            metadata  context_len  \n",
       "0  {'file_type': '.md', 'language': 'en', 'source...  1291.111111  \n",
       "2  {'file_type': '.md', 'language': 'en', 'source...  1291.111111  \n",
       "4  {'file_type': '.md', 'language': 'en', 'source...  1291.111111  \n",
       "5  {'file_type': '.md', 'language': 'en', 'source...  2186.111111  \n",
       "6  {'file_type': '.md', 'language': 'en', 'source...  2186.111111  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(table.data, columns=table.columns)\n",
    "df = df.dropna()\n",
    "df = df.assign(context_len = lambda df: df.page_content.str.len()/3.6)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d61c89c2-831f-4996-9f07-3965ba839858",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2091"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90391542-9e78-46ea-a197-0bc915f54a44",
   "metadata": {},
   "source": [
    "Let's prepare the training dataset now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dae08b1-5519-43e4-ba28-099950a0bd63",
   "metadata": {},
   "source": [
    "If you use CodeLLama we need to format the instructions accordingly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbb5948d-1b37-46b6-b6e1-5b1c65498bba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "B_INST, E_INST = \"[INST] \", \" [/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "EOS = \"</s>\"\n",
    "\n",
    "prompt_format = (\n",
    "    B_INST\n",
    "    + B_SYS\n",
    "    + \"You are an AI assistant designed to assist developers with everyday tasks related to Weight & Biases \"\n",
    "    + \"and provide helpful information. As an expert in the open-source python SDK wandb answer the following \"\n",
    "    # + \"question based on the context below. Answer in formatted Markdown.\\n\"\n",
    "    + \"question below. Answer in formatted Markdown.\\n\"\n",
    "    + \"{page_content}\"\n",
    "    + E_SYS\n",
    "    + \"{question}\"\n",
    "    + E_INST\n",
    "    + \"\\n[W&B]\\n\"\n",
    "    + \"{answer}\"\n",
    "    + \"\\n[/W&B]\"\n",
    "    + EOS\n",
    ")\n",
    "\n",
    "def format_text(row):\n",
    "    return prompt_format.format_map(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20ab80e2-9206-421e-acf9-d1d8d67baab3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<SYS>>\n",
      "You are an AI assistant designed to assist developers with everyday tasks related to Weight & Biases and provide helpful information. As an expert in the open-source python SDK wandb answer the following question below. Answer in formatted Markdown.\n",
      "{page_content}\n",
      "<</SYS>>\n",
      "\n",
      "{question} [/INST]\n",
      "[W&B]\n",
      "{answer}\n",
      "[/W&B]</s>\n"
     ]
    }
   ],
   "source": [
    "print(prompt_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da903861-dce9-466d-839e-67d937b228e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<SYS>>\n",
      "You are an AI assistant designed to assist developers with everyday tasks related to Weight & Biases and provide helpful information. As an expert in the open-source python SDK wandb answer the following question below. Answer in formatted Markdown.\n",
      "import Tabs from â€˜@theme/Tabsâ€™;  \n",
      "\n",
      "import TabItem from â€˜@theme/TabItemâ€™;\n",
      "\n",
      "\n",
      "# Quickstart\n",
      "\n",
      "\n",
      "Install W&B and start tracking your machine learning experiments in minutes.\n",
      "\n",
      "\n",
      "## 1. Create an account and install W&B\n",
      "\n",
      "\n",
      "Before you get started, make sure you create an account and install W&B:\n",
      "\n",
      "\n",
      "1. Sign up for a free account at <https://wandb.ai/site> and then login to your wandb account.\n",
      "2. Install the wandb library on your machine in a Python 3 environment using `pip`.\n",
      "\n",
      "\n",
      "\n",
      "The following code snippets demonstrate how to install and log into W&B using the W&B CLI and Python Library:\n",
      "\n",
      "\n",
      "\n",
      "Install the CLI and Python library for interacting with the Weights and Biases API:\n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "pip install wandb\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "Install the CLI and Python library for interacting with the Weights and Biases API:\n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "!pip install wandb\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "## 2. Log in to W&B\n",
      "\n",
      "\n",
      "\n",
      "Next, log in to W&B:\n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "wandb login\n",
      "\n",
      "```\n",
      "\n",
      "Or if you are using W&B Server:\n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "wandb login --host=http://wandb.your-shared-local-host.com\n",
      "\n",
      "```\n",
      "\n",
      "Provide your API key when prompted.\n",
      "\n",
      "\n",
      "\n",
      "Next, import the W&B Python SDK and log in:\n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "wandb.login()\n",
      "\n",
      "```\n",
      "\n",
      "Provide your API key when prompted.  \n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## 3. Start a run and track hyperparameters\n",
      "\n",
      "\n",
      "Initialize a W&B Run object in your Python script or notebook with `wandb.init()` and pass a dictionary to the `config` parameter with key-value pairs of hyperparameter names and values:\n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "run = wandb.init(\n",
      "    # Set the project where this run will be logged\n",
      "    project=\"my-awesome-project\",\n",
      "    # Track hyperparameters and run metadata\n",
      "    config={\n",
      "        \"learning_rate\": 0.01,\n",
      "        \"epochs\": 10,\n",
      "    })\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "A run is the basic building block of W&B. You will use them often to track metrics, create logs, create jobs, and more.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Putting it all together\n",
      "\n",
      "\n",
      "Putting it all together, your training script might look similar to the following code example. The highlighted code shows W&B-specific code.   \n",
      "\n",
      "Note that we added code that mimics machine learning training.\n",
      "\n",
      "\n",
      "\n",
      "```\n",
      "# train.py\n",
      "import wandb\n",
      "import random # for demo script\n",
      "\n",
      "# highlight-next-line\n",
      "wandb.login()\n",
      "\n",
      "epochs=10\n",
      "lr=0.01\n",
      "\n",
      "# highlight-start\n",
      "run = wandb.init(\n",
      "    # Set the project where this run will be logged\n",
      "    project=\"my-awesome-project\",\n",
      "    # Track hyperparameters and run metadata\n",
      "    config={\n",
      "        \"learning_rate\": lr,\n",
      "        \"epochs\": epochs,\n",
      "    })\n",
      "# highlight-end    \n",
      "\n",
      "offset = random.random() / 5\n",
      "print(f\"lr: {lr}\")\n",
      "\n",
      "# simulating a training run\n",
      "for epoch in range(2, epochs):\n",
      "    acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
      "    loss = 2 ** -epoch + random.random() / epoch + offset\n",
      "    print(f\"epoch={epoch}, accuracy={acc}, loss={loss}\")\n",
      "    # highlight-next-line\n",
      "    wandb.log({\"accuracy\": acc, \"loss\": loss})\n",
      "\n",
      "# run.log_code()\n",
      "\n",
      "```\n",
      "\n",
      "Thatâ€™s it! Navigate to the W&B App at <https://wandb.ai/home> to view how the metrics we logged with W&B (accuracy and loss) improved during each training step.\n",
      "\n",
      "\n",
      "\n",
      "The image above (click to expand) shows the loss and accuracy that was tracked from each time we ran the script above. Each run object that was created is show within the **Runs** column. Each run name is randomly generated.\n",
      "\n",
      "\n",
      "## Whatâ€™s next?\n",
      "\n",
      "\n",
      "\n",
      "Explore the rest of the W&B ecosystem.\n",
      "\n",
      "\n",
      "1. Check out W&B Integrations to learn how to integrate W&B with your ML framework such as PyTorch, ML library such as Hugging Face, or ML service such as SageMaker.\n",
      "2. Organize runs, embed and automate visualizations, describe your findings, and share updates with collaborators with W&B Reports.\n",
      "3. Create W&B Artifacts to track datasets, models, dependencies, and results through each step of your machine learning pipeline.\n",
      "4. Automate hyperparameter search and explore the space of possible models with W&B Sweeps.\n",
      "5. Understand your datasets, visualize model predictions, and share insights in a central dashboard.\n",
      "\n",
      "\n",
      "\n",
      "## Common Questions\n",
      "\n",
      "\n",
      "**Where do I find my API key?**  \n",
      "\n",
      "Once youâ€™ve signed in to www.wandb.ai, the API key will be on the Authorize page.\n",
      "\n",
      "\n",
      "**How do I use W&B in an automated environment?**  \n",
      "\n",
      "If you are training models in an automated environment where itâ€™s inconvenient to run shell commands, such as Googleâ€™s CloudML, you should look at our guide to configuration with Environment Variables.\n",
      "\n",
      "\n",
      "**Do you offer local, on-prem installs?**  \n",
      "\n",
      "Yes, you can privately host W&B locally on your own machines or in a private cloud, try this quick tutorial notebook to see how. Note, to login to wandb local server you can set the host flag to the address of the local instance. \n",
      "\n",
      "\n",
      "**How do I turn off wandb logging temporarily?**  \n",
      "\n",
      "If are testing code and want to disable wandb syncing, set the environment variable `WANDB_MODE=offline`.\n",
      "\n",
      "\n",
      "<</SYS>>\n",
      "\n",
      "What is a 'run' in W&B and what can I use it for? [/INST]\n",
      "[W&B]\n",
      "A 'run' in W&B is the fundamental unit that you can use to track various aspects of your machine learning experiments. Once you initialize a W&B Run object in your Python script or notebook using `wandb.init()`, you can pass a dictionary to the `config` parameter where the key-value pairs are your hyperparameters with their corresponding values. You can use a 'run' to track metrics, create logs, jobs and do many more things.\n",
      "[/W&B]</s>\n"
     ]
    }
   ],
   "source": [
    "one_example = format_text(df.iloc[0])\n",
    "print(one_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf19de4-c29a-4803-aad1-8eb0b9c32da5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's compute the format over all the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "369e92cb-d51d-4f97-93e0-bb3c709eb126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"text\"] = df.apply(format_text, axis=1)\n",
    "\n",
    "# print(df.iloc[200][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c18f6fe4-6573-4901-ac44-aa51d0400452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_json(\"wandb_questions_ds.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01efd5c0-1fec-4c76-bd6e-1ab182deb7c3",
   "metadata": {},
   "source": [
    "## Saving your work to W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3867767-df18-4866-9c78-ca623ad9b205",
   "metadata": {},
   "source": [
    "We should log this to W&B so we can inspect the dataset interactively using W&B Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "902581de-ada6-44c4-b399-ef24845948e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa88fbf4a8647aaac756f3e82875719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='43.532 MB of 59.734 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.7287â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cosmic-plasma-7</strong> at: <a href='https://wandb.ai/capecape/wandbot_llm/runs/yrkl2cco' target=\"_blank\">https://wandb.ai/capecape/wandbot_llm/runs/yrkl2cco</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231018_121927-yrkl2cco/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = wandb.Table(dataframe=df)\n",
    "wandb.log({\"wandb_questions_ds\": table})\n",
    "\n",
    "# let's also save a the dataset at this stage\n",
    "at = wandb.Artifact(\n",
    "    name=\"wandb_questions_ds\", \n",
    "    type=\"dataset\",\n",
    "    description=\"A wandbot dataset of questions and answers about W&B for training (non tokenized)\",\n",
    "    metadata={\"prompt_format\": prompt_format,\n",
    "              \"length\": len(df),\n",
    "             }\n",
    ")\n",
    "at.add_file(\"wandb_questions_ds.jsonl\")\n",
    "wandb.log_artifact(at)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdebe295-f927-406f-b790-27bc059abab1",
   "metadata": {},
   "source": [
    "## Tokenizing and saving the preprocessing\n",
    "We can save time during training by pre-processing the dataset and loading directly a tokenized dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5380e7bd-66f3-4237-a901-fe935a249982",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"codellama/CodeLlama-7b-Instruct-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20aaffb3-d181-4c34-a58d-3e9c78a16d14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577b24aaca84420bb5a120cd62e52465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/749 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8876afee598a43549726129ebb10e95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c6dd2bbf874d239732f8c9cc01d740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97ccf4263514ef7b5aab82dade08cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_auth_token=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ed5fc-a178-424d-8bc5-56f452dc3487",
   "metadata": {},
   "source": [
    "we can convert the data to a huggingface parquet-based dataset for fast loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33ad3e77-c60c-46a1-9fef-432d412bccc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/cape/wandbot_llm/wandb/run-20231018_122024-qb37k4d1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/capecape/wandbot_llm/runs/qb37k4d1' target=\"_blank\">laced-sun-8</a></strong> to <a href='https://wandb.ai/capecape/wandbot_llm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/capecape/wandbot_llm' target=\"_blank\">https://wandb.ai/capecape/wandbot_llm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/capecape/wandbot_llm/runs/qb37k4d1' target=\"_blank\">https://wandb.ai/capecape/wandbot_llm/runs/qb37k4d1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "wandb.init(project=WANDB_PROJECT, job_type=\"tokenizing\")\n",
    "artifact = wandb.use_artifact('capecape/aws_llm_workshop/wandb_questions_ds:v0', type='dataset')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d894909-a161-4806-832f-0da72a580860",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a373e4153d467f8c86d80b62be63de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91581736bad84a759a1e40f9eac4dd31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13e79c8456d4398935281436d1f1680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'question', 'answer', 'page_content', 'metadata', 'context_len', 'text'],\n",
       "    num_rows: 2091\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = load_dataset(\n",
    "    path=\".\", \n",
    "    data_files=f\"{artifact_dir}/wandb_questions_ds.jsonl\", \n",
    "    split=\"train\")\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676fbde0-d780-4beb-94dd-fff1a5a617ac",
   "metadata": {},
   "source": [
    "one sample looks like this ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a4aa0e2-c9b3-4065-8c4a-ca24f8bfd856",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.select_columns([\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5df85d-be1f-4726-92c8-73e94146ea5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Packing and chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac52401-ea01-44bb-95d7-b11f8aa34b59",
   "metadata": {},
   "source": [
    "We define some helper functions to pack our samples into sequences of a given length and then tokenize them.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0eb36f2-6dbf-4f13-b8ea-1ba2effc709c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1711b645e143a88b0c4839092cd7e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2091 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '[INST] <<SYS>>\\nYou are an AI assistant designed to assist developers with everyday tasks related to Weight & Biasesand provide helpful information. As an expert in the open-source python SDK wandb answer the followingquestion below. Answer in formatted Markdown.\\nimport Tabs from â€˜@theme/Tabsâ€™;  \\n\\nimport TabItem from â€˜@theme/TabItemâ€™;\\n\\n\\n# Quickstart\\n\\n\\nInstall W&B and start tracking your machine learning experiments in minutes.\\n\\n\\n## 1. Create an account and install W&B\\n\\n\\nBefore you get started, make sure you create an account and install W&B:\\n\\n\\n1. Sign up for a free account at <https://wandb.ai/site> and then login to your wandb account.\\n2. Install the wandb library on your machine in a Python 3 environment using `pip`.\\n\\n\\n\\nThe following code snippets demonstrate how to install and log into W&B using the W&B CLI and Python Library:\\n\\n\\n\\nInstall the CLI and Python library for interacting with the Weights and Biases API:\\n\\n\\n\\n```\\npip install wandb\\n\\n```\\n\\n\\nInstall the CLI and Python library for interacting with the Weights and Biases API:\\n\\n\\n\\n```\\n!pip install wandb\\n\\n```\\n\\n\\n## 2. Log in to W&B\\n\\n\\n\\nNext, log in to W&B:\\n\\n\\n\\n```\\nwandb login\\n\\n```\\n\\nOr if you are using W&B Server:\\n\\n\\n\\n```\\nwandb login --host=http://wandb.your-shared-local-host.com\\n\\n```\\n\\nProvide your API key when prompted.\\n\\n\\n\\nNext, import the W&B Python SDK and log in:\\n\\n\\n\\n```\\nwandb.login()\\n\\n```\\n\\nProvide your API key when prompted.  \\n\\n  \\n\\n\\n\\n\\n## 3. Start a run and track hyperparameters\\n\\n\\nInitialize a W&B Run object in your Python script or notebook with `wandb.init()` and pass a dictionary to the `config` parameter with key-value pairs of hyperparameter names and values:\\n\\n\\n\\n```\\nrun = wandb.init(\\n    # Set the project where this run will be logged\\n    project=\"my-awesome-project\",\\n    # Track hyperparameters and run metadata\\n    config={\\n        \"learning_rate\": 0.01,\\n        \"epochs\": 10,\\n    })\\n\\n```\\n\\n\\nA run is the basic building block of W&B. You will use them often to track metrics, create logs, create jobs, and more.\\n\\n\\n\\n\\n## Putting it all together\\n\\n\\nPutting it all together, your training script might look similar to the following code example. The highlighted code shows W&B-specific code.   \\n\\nNote that we added code that mimics machine learning training.\\n\\n\\n\\n```\\n# train.py\\nimport wandb\\nimport random # for demo script\\n\\n# highlight-next-line\\nwandb.login()\\n\\nepochs=10\\nlr=0.01\\n\\n# highlight-start\\nrun = wandb.init(\\n    # Set the project where this run will be logged\\n    project=\"my-awesome-project\",\\n    # Track hyperparameters and run metadata\\n    config={\\n        \"learning_rate\": lr,\\n        \"epochs\": epochs,\\n    })\\n# highlight-end    \\n\\noffset = random.random() / 5\\nprint(f\"lr: {lr}\")\\n\\n# simulating a training run\\nfor epoch in range(2, epochs):\\n    acc = 1 - 2 ** -epoch - random.random() / epoch - offset\\n    loss = 2 ** -epoch + random.random() / epoch + offset\\n    print(f\"epoch={epoch}, accuracy={acc}, loss={loss}\")\\n    # highlight-next-line\\n    wandb.log({\"accuracy\": acc, \"loss\": loss})\\n\\n# run.log_code()\\n\\n```\\n\\nThatâ€™s it! Navigate to the W&B App at <https://wandb.ai/home> to view how the metrics we logged with W&B (accuracy and loss) improved during each training step.\\n\\n\\n\\nThe image above (click to expand) shows the loss and accuracy that was tracked from each time we ran the script above. Each run object that was created is show within the **Runs** column. Each run name is randomly generated.\\n\\n\\n## Whatâ€™s next?\\n\\n\\n\\nExplore the rest of the W&B ecosystem.\\n\\n\\n1. Check out W&B Integrations to learn how to integrate W&B with your ML framework such as PyTorch, ML library such as Hugging Face, or ML service such as SageMaker.\\n2. Organize runs, embed and automate visualizations, describe your findings, and share updates with collaborators with W&B Reports.\\n3. Create W&B Artifacts to track datasets, models, dependencies, and results through each step of your machine learning pipeline.\\n4. Automate hyperparameter search and explore the space of possible models with W&B Sweeps.\\n5. Understand your datasets, visualize model predictions, and share insights in a central dashboard.\\n\\n\\n\\n## Common Questions\\n\\n\\n**Where do I find my API key?**  \\n\\nOnce youâ€™ve signed in to www.wandb.ai, the API key will be on the Authorize page.\\n\\n\\n**How do I use W&B in an automated environment?**  \\n\\nIf you are training models in an automated environment where itâ€™s inconvenient to run shell commands, such as Googleâ€™s CloudML, you should look at our guide to configuration with Environment Variables.\\n\\n\\n**Do you offer local, on-prem installs?**  \\n\\nYes, you can privately host W&B locally on your own machines or in a private cloud, try this quick tutorial notebook to see how. Note, to login to wandb local server you can set the host flag to the address of the local instance. \\n\\n\\n**How do I turn off wandb logging temporarily?**  \\n\\nIf are testing code and want to disable wandb syncing, set the environment variable `WANDB_MODE=offline`.\\n\\n\\n<</SYS>>\\n\\nHow can I get started with W&B after creating an account? [/INST]\\n[W&B]\\nTo get started with W&B after creating an account, you first need to install the W&B library on your machine in a Python 3 environment using pip. Use the following command to install:\\n```\\npip install wandb\\n```\\nNext, you need to login to W&B. You can do this in your Python code using the following command:\\n```\\nwandb.login()\\n```\\nYou will be prompted to provide your API key. After that, to start a run and track hyperparameters, you can initialize a W&B Run object in your Python script or notebook with `wandb.init()` and pass a dictionary to the `config` parameter with key-value pairs of hyperparameter names and values. Here\\'s an example:\\n```\\nrun = wandb.init(\\n    # Set the project where this run will be logged\\n    project=\"my-awesome-project\",\\n    # Track hyperparameters and run metadata\\n    config={\\n        \"learning_rate\": 0.01,\\n        \"epochs\": 10,\\n    })\\n```\\nThis will start a run in your project, tracking the specified hyperparameters.\\n[/W&B]</s>'}</s>\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# template dataset to add prompt to each sample\n",
    "def template_dataset(sample):\n",
    "    sample[\"text\"] = f\"{sample}{tokenizer.eos_token}\"\n",
    "    return sample\n",
    "\n",
    "\n",
    "# apply prompt template per sample\n",
    "train_dataset = train_dataset.map(template_dataset)\n",
    "# print random sample\n",
    "print(train_dataset[randint(0, len(train_dataset))][\"text\"])\n",
    "\n",
    "# empty list to save remainder from batches to use in next batch\n",
    "remainder = {\"input_ids\": [], \"attention_mask\": [], \"token_type_ids\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec8e2766-5b3a-4424-82e6-1cf5ef45da1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f5b41f388246a99b123aeb7b715ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2091 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6caf6370b30b4ebfa27dfdb3b04dc849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2091 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 4907\n"
     ]
    }
   ],
   "source": [
    "def chunk(sample, chunk_length=1024):\n",
    "    # define global remainder variable to save remainder from batches to use in next batch\n",
    "    global remainder\n",
    "    # Concatenate all texts and add remainder from previous batch\n",
    "    concatenated_examples = {k: list(chain(*sample[k])) for k in sample.keys()}\n",
    "    concatenated_examples = {k: remainder[k] + concatenated_examples[k] for k in concatenated_examples.keys()}\n",
    "    # get total number of tokens for batch\n",
    "    batch_total_length = len(concatenated_examples[list(sample.keys())[0]])\n",
    "\n",
    "    # get max number of chunks for batch\n",
    "    if batch_total_length >= chunk_length:\n",
    "        batch_chunk_length = (batch_total_length // chunk_length) * chunk_length\n",
    "\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_length] for i in range(0, batch_chunk_length, chunk_length)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # add remainder to global variable for next batch\n",
    "    remainder = {k: concatenated_examples[k][batch_chunk_length:] for k in concatenated_examples.keys()}\n",
    "    # prepare labels\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "\n",
    "# tokenize and chunk dataset\n",
    "lm_dataset = train_dataset.map(\n",
    "    lambda sample: tokenizer(sample[\"text\"]), batched=True, remove_columns=list(train_dataset.features)\n",
    ").map(\n",
    "    partial(chunk, chunk_length=1024),\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "# Print total number of samples\n",
    "print(f\"Total number of samples: {len(lm_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd4726a-5381-4a56-8e5a-59fdfffb8c7c",
   "metadata": {},
   "source": [
    "## Save to a bucket and W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb0ecae-ed90-4f83-a34d-99e46daa4d1b",
   "metadata": {},
   "source": [
    "We are now going to use W&B Aritfacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "322268d9-80a8-4f67-bf55-76cf4773ca95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0502e1f9fad42a8b936f931c23e07d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4907 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded data to:\n",
      "training dataset to: ./wandbot_train_ds\n"
     ]
    }
   ],
   "source": [
    "training_input_path = \"./wandbot_train_ds\"\n",
    "\n",
    "lm_dataset.save_to_disk(training_input_path)\n",
    "\n",
    "print(\"uploaded data to:\")\n",
    "print(f\"training dataset to: {training_input_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f92d3c9a-f01d-4b6e-8a20-ab707918a0e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "at = wandb.Artifact(\n",
    "    name=\"wandbot_dataset_tokenized\", \n",
    "    type=\"dataset\",\n",
    "    description=\"A wandbot dataset of questions and answers about W&B - CodeLLama tokenized\",\n",
    "    metadata={\"model_name\": MODEL_NAME, \"tokenizer\": MODEL_NAME},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7edcf658-cd05-46de-bc30-45c27a8f4853",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./wandbot_train_ds)... Done. 0.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Artifact wandbot_dataset_tokenized>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at.add_dir(training_input_path)\n",
    "wandb.log_artifact(at)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd2e08-939d-4269-8d65-8ae3684fb3de",
   "metadata": {},
   "source": [
    "Let's finish this run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c3900fa-e7b2-4b59-be6f-d9d2459e237c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">laced-sun-8</strong> at: <a href='https://wandb.ai/capecape/wandbot_llm/runs/qb37k4d1' target=\"_blank\">https://wandb.ai/capecape/wandbot_llm/runs/qb37k4d1</a><br/>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231018_122024-qb37k4d1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b63367-19f7-4bb6-b2f8-44e200c74df6",
   "metadata": {},
   "source": [
    "# Eval Dataset\n",
    "We prepared a set of questions from `wandbot` that were gathered and curated by my colleague Ayush T. God's work here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acd347ea-262d-4e62-86e0-3920fafc471d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import wandb\n",
    "\n",
    "wandb.init(project=WANDB_PROJECT, job_type=\"eval_preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5acaa58-a6da-45ea-bcc8-bc8bd7e9f4da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./artifacts/run-kinbxic4-responses:v0'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_artifacts = wandb.use_artifact(RAW_EVAL_DATASET_ARTIFACT, type='run_table')\n",
    "question_artifacts.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5b79682-7f83-4771-895b-c1b7bfe3fc2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(question_artifacts.file()) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "columns = data[\"columns\"]\n",
    "data = data[\"data\"]\n",
    "eval_df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c78e291-ce2d-4061-9720-71f8bdf317ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>retrieved_context</th>\n",
       "      <th>generated_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey I have a question about using wandb with f...</td>\n",
       "      <td>[`wandb.init()` returns a run object, and you ...</td>\n",
       "      <td>The initialization of `wandb.init()` should be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey with wandb is it possible to link from the...</td>\n",
       "      <td>[### How do I best log models from runs in a s...</td>\n",
       "      <td>Yes, you can link to the best run from a sweep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am training a spacy textcat model. This proc...</td>\n",
       "      <td>[### Model Architecture\\n\\nOur config also def...</td>\n",
       "      <td>To log the best model's metrics instead of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explain how I can version datasets with Weight...</td>\n",
       "      <td>[ # A 3-in-1 Intro to Weights &amp; Biases: Comput...</td>\n",
       "      <td>Weights &amp; Biases provides a feature called Art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm using   env = SubprocVecEnv(\\n        [mak...</td>\n",
       "      <td>[## WandbCallback å¼•æ•°\\n\\n| å¼•æ•° | ä½¿ç”¨æ³• | | --- | -...</td>\n",
       "      <td>To record a video for a specific subprocess en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Hey I have a question about using wandb with f...   \n",
       "1  Hey with wandb is it possible to link from the...   \n",
       "2  I am training a spacy textcat model. This proc...   \n",
       "3  Explain how I can version datasets with Weight...   \n",
       "4  I'm using   env = SubprocVecEnv(\\n        [mak...   \n",
       "\n",
       "                                   retrieved_context  \\\n",
       "0  [`wandb.init()` returns a run object, and you ...   \n",
       "1  [### How do I best log models from runs in a s...   \n",
       "2  [### Model Architecture\\n\\nOur config also def...   \n",
       "3  [ # A 3-in-1 Intro to Weights & Biases: Comput...   \n",
       "4  [## WandbCallback å¼•æ•°\\n\\n| å¼•æ•° | ä½¿ç”¨æ³• | | --- | -...   \n",
       "\n",
       "                                  generated_response  \n",
       "0  The initialization of `wandb.init()` should be...  \n",
       "1  Yes, you can link to the best run from a sweep...  \n",
       "2  To log the best model's metrics instead of the...  \n",
       "3  Weights & Biases provides a feature called Art...  \n",
       "4  To record a video for a specific subprocess en...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb58d1b-0b17-49e3-8768-b9baeb3d9046",
   "metadata": {},
   "source": [
    "Let's remove retrieved Japanese text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646a2941-5ea9-47be-98e2-8731387f6114",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Clean up and prepare (pandas workout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fee50101-b6a7-4e08-ab2f-e426b5e9840c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def contains_japanese(text):\n",
    "    for char in text:\n",
    "        if 'ä¸€' <= char <= 'é¾¥':\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "365bff6a-c0bc-4765-8044-854df497d29b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = \"## WandbCallback å¼•æ•°\\n\\n| å¼•æ•° | ä½¿ç”¨æ³• |\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "addabb0a-5569-4c26-9b29-17484a20832d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df[\"retrieved_context_en\"] = [[ctx for ctx in ctxs if not contains_japanese(ctx)] for ctxs in eval_df.retrieved_context.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd18bd4e-aeb5-4ac7-a547-08252188b048",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>retrieved_context</th>\n",
       "      <th>generated_response</th>\n",
       "      <th>retrieved_context_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey I have a question about using wandb with f...</td>\n",
       "      <td>[`wandb.init()` returns a run object, and you ...</td>\n",
       "      <td>The initialization of `wandb.init()` should be...</td>\n",
       "      <td>[`wandb.init()` returns a run object, and you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey with wandb is it possible to link from the...</td>\n",
       "      <td>[### How do I best log models from runs in a s...</td>\n",
       "      <td>Yes, you can link to the best run from a sweep...</td>\n",
       "      <td>[### How do I best log models from runs in a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am training a spacy textcat model. This proc...</td>\n",
       "      <td>[### Model Architecture\\n\\nOur config also def...</td>\n",
       "      <td>To log the best model's metrics instead of the...</td>\n",
       "      <td>[### Model Architecture\\n\\nOur config also def...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explain how I can version datasets with Weight...</td>\n",
       "      <td>[ # A 3-in-1 Intro to Weights &amp; Biases: Comput...</td>\n",
       "      <td>Weights &amp; Biases provides a feature called Art...</td>\n",
       "      <td>[ # A 3-in-1 Intro to Weights &amp; Biases: Comput...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm using   env = SubprocVecEnv(\\n        [mak...</td>\n",
       "      <td>[## WandbCallback å¼•æ•°\\n\\n| å¼•æ•° | ä½¿ç”¨æ³• | | --- | -...</td>\n",
       "      <td>To record a video for a specific subprocess en...</td>\n",
       "      <td>[## Basic Example\\n\\nThe W&amp;B SB3 integration u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Hey I have a question about using wandb with f...   \n",
       "1  Hey with wandb is it possible to link from the...   \n",
       "2  I am training a spacy textcat model. This proc...   \n",
       "3  Explain how I can version datasets with Weight...   \n",
       "4  I'm using   env = SubprocVecEnv(\\n        [mak...   \n",
       "\n",
       "                                   retrieved_context  \\\n",
       "0  [`wandb.init()` returns a run object, and you ...   \n",
       "1  [### How do I best log models from runs in a s...   \n",
       "2  [### Model Architecture\\n\\nOur config also def...   \n",
       "3  [ # A 3-in-1 Intro to Weights & Biases: Comput...   \n",
       "4  [## WandbCallback å¼•æ•°\\n\\n| å¼•æ•° | ä½¿ç”¨æ³• | | --- | -...   \n",
       "\n",
       "                                  generated_response  \\\n",
       "0  The initialization of `wandb.init()` should be...   \n",
       "1  Yes, you can link to the best run from a sweep...   \n",
       "2  To log the best model's metrics instead of the...   \n",
       "3  Weights & Biases provides a feature called Art...   \n",
       "4  To record a video for a specific subprocess en...   \n",
       "\n",
       "                                retrieved_context_en  \n",
       "0  [`wandb.init()` returns a run object, and you ...  \n",
       "1  [### How do I best log models from runs in a s...  \n",
       "2  [### Model Architecture\\n\\nOur config also def...  \n",
       "3  [ # A 3-in-1 Intro to Weights & Biases: Comput...  \n",
       "4  [## Basic Example\\n\\nThe W&B SB3 integration u...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12b8732a-e42e-4f19-b8ee-baceb673f32d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df[\"retrieved_context_stuff\"] = [\"\\n\".join(ctxs) for ctxs in eval_df.retrieved_context_en.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14459a92-98fe-4674-9e8a-7afdaf7c1095",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>retrieved_context</th>\n",
       "      <th>generated_response</th>\n",
       "      <th>retrieved_context_en</th>\n",
       "      <th>retrieved_context_stuff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey I have a question about using wandb with f...</td>\n",
       "      <td>[`wandb.init()` returns a run object, and you ...</td>\n",
       "      <td>The initialization of `wandb.init()` should be...</td>\n",
       "      <td>[`wandb.init()` returns a run object, and you ...</td>\n",
       "      <td>`wandb.init()` returns a run object, and you c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey with wandb is it possible to link from the...</td>\n",
       "      <td>[### How do I best log models from runs in a s...</td>\n",
       "      <td>Yes, you can link to the best run from a sweep...</td>\n",
       "      <td>[### How do I best log models from runs in a s...</td>\n",
       "      <td>### How do I best log models from runs in a sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am training a spacy textcat model. This proc...</td>\n",
       "      <td>[### Model Architecture\\n\\nOur config also def...</td>\n",
       "      <td>To log the best model's metrics instead of the...</td>\n",
       "      <td>[### Model Architecture\\n\\nOur config also def...</td>\n",
       "      <td>### Model Architecture\\n\\nOur config also defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explain how I can version datasets with Weight...</td>\n",
       "      <td>[ # A 3-in-1 Intro to Weights &amp; Biases: Comput...</td>\n",
       "      <td>Weights &amp; Biases provides a feature called Art...</td>\n",
       "      <td>[ # A 3-in-1 Intro to Weights &amp; Biases: Comput...</td>\n",
       "      <td># A 3-in-1 Intro to Weights &amp; Biases: Compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm using   env = SubprocVecEnv(\\n        [mak...</td>\n",
       "      <td>[## WandbCallback å¼•æ•°\\n\\n| å¼•æ•° | ä½¿ç”¨æ³• | | --- | -...</td>\n",
       "      <td>To record a video for a specific subprocess en...</td>\n",
       "      <td>[## Basic Example\\n\\nThe W&amp;B SB3 integration u...</td>\n",
       "      <td>## Basic Example\\n\\nThe W&amp;B SB3 integration us...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Hey I have a question about using wandb with f...   \n",
       "1  Hey with wandb is it possible to link from the...   \n",
       "2  I am training a spacy textcat model. This proc...   \n",
       "3  Explain how I can version datasets with Weight...   \n",
       "4  I'm using   env = SubprocVecEnv(\\n        [mak...   \n",
       "\n",
       "                                   retrieved_context  \\\n",
       "0  [`wandb.init()` returns a run object, and you ...   \n",
       "1  [### How do I best log models from runs in a s...   \n",
       "2  [### Model Architecture\\n\\nOur config also def...   \n",
       "3  [ # A 3-in-1 Intro to Weights & Biases: Comput...   \n",
       "4  [## WandbCallback å¼•æ•°\\n\\n| å¼•æ•° | ä½¿ç”¨æ³• | | --- | -...   \n",
       "\n",
       "                                  generated_response  \\\n",
       "0  The initialization of `wandb.init()` should be...   \n",
       "1  Yes, you can link to the best run from a sweep...   \n",
       "2  To log the best model's metrics instead of the...   \n",
       "3  Weights & Biases provides a feature called Art...   \n",
       "4  To record a video for a specific subprocess en...   \n",
       "\n",
       "                                retrieved_context_en  \\\n",
       "0  [`wandb.init()` returns a run object, and you ...   \n",
       "1  [### How do I best log models from runs in a s...   \n",
       "2  [### Model Architecture\\n\\nOur config also def...   \n",
       "3  [ # A 3-in-1 Intro to Weights & Biases: Comput...   \n",
       "4  [## Basic Example\\n\\nThe W&B SB3 integration u...   \n",
       "\n",
       "                             retrieved_context_stuff  \n",
       "0  `wandb.init()` returns a run object, and you c...  \n",
       "1  ### How do I best log models from runs in a sw...  \n",
       "2  ### Model Architecture\\n\\nOur config also defi...  \n",
       "3   # A 3-in-1 Intro to Weights & Biases: Compute...  \n",
       "4  ## Basic Example\\n\\nThe W&B SB3 integration us...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61dd549f-1923-4e81-ba84-a5fa5dcbb297",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df = eval_df.assign(tokens = eval_df['retrieved_context_stuff'].str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a37a312e-08cf-4406-99d5-87342709dcc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>retrieved_context</th>\n",
       "      <th>generated_response</th>\n",
       "      <th>retrieved_context_en</th>\n",
       "      <th>retrieved_context_stuff</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey I have a question about using wandb with f...</td>\n",
       "      <td>[`wandb.init()` returns a run object, and you ...</td>\n",
       "      <td>The initialization of `wandb.init()` should be...</td>\n",
       "      <td>[`wandb.init()` returns a run object, and you ...</td>\n",
       "      <td>`wandb.init()` returns a run object, and you c...</td>\n",
       "      <td>15505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey with wandb is it possible to link from the...</td>\n",
       "      <td>[### How do I best log models from runs in a s...</td>\n",
       "      <td>Yes, you can link to the best run from a sweep...</td>\n",
       "      <td>[### How do I best log models from runs in a s...</td>\n",
       "      <td>### How do I best log models from runs in a sw...</td>\n",
       "      <td>13161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am training a spacy textcat model. This proc...</td>\n",
       "      <td>[### Model Architecture\\n\\nOur config also def...</td>\n",
       "      <td>To log the best model's metrics instead of the...</td>\n",
       "      <td>[### Model Architecture\\n\\nOur config also def...</td>\n",
       "      <td>### Model Architecture\\n\\nOur config also defi...</td>\n",
       "      <td>17812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explain how I can version datasets with Weight...</td>\n",
       "      <td>[ # A 3-in-1 Intro to Weights &amp; Biases: Comput...</td>\n",
       "      <td>Weights &amp; Biases provides a feature called Art...</td>\n",
       "      <td>[ # A 3-in-1 Intro to Weights &amp; Biases: Comput...</td>\n",
       "      <td># A 3-in-1 Intro to Weights &amp; Biases: Compute...</td>\n",
       "      <td>12755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm using   env = SubprocVecEnv(\\n        [mak...</td>\n",
       "      <td>[## WandbCallback å¼•æ•°\\n\\n| å¼•æ•° | ä½¿ç”¨æ³• | | --- | -...</td>\n",
       "      <td>To record a video for a specific subprocess en...</td>\n",
       "      <td>[## Basic Example\\n\\nThe W&amp;B SB3 integration u...</td>\n",
       "      <td>## Basic Example\\n\\nThe W&amp;B SB3 integration us...</td>\n",
       "      <td>15480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Hey I have a question about using wandb with f...   \n",
       "1  Hey with wandb is it possible to link from the...   \n",
       "2  I am training a spacy textcat model. This proc...   \n",
       "3  Explain how I can version datasets with Weight...   \n",
       "4  I'm using   env = SubprocVecEnv(\\n        [mak...   \n",
       "\n",
       "                                   retrieved_context  \\\n",
       "0  [`wandb.init()` returns a run object, and you ...   \n",
       "1  [### How do I best log models from runs in a s...   \n",
       "2  [### Model Architecture\\n\\nOur config also def...   \n",
       "3  [ # A 3-in-1 Intro to Weights & Biases: Comput...   \n",
       "4  [## WandbCallback å¼•æ•°\\n\\n| å¼•æ•° | ä½¿ç”¨æ³• | | --- | -...   \n",
       "\n",
       "                                  generated_response  \\\n",
       "0  The initialization of `wandb.init()` should be...   \n",
       "1  Yes, you can link to the best run from a sweep...   \n",
       "2  To log the best model's metrics instead of the...   \n",
       "3  Weights & Biases provides a feature called Art...   \n",
       "4  To record a video for a specific subprocess en...   \n",
       "\n",
       "                                retrieved_context_en  \\\n",
       "0  [`wandb.init()` returns a run object, and you ...   \n",
       "1  [### How do I best log models from runs in a s...   \n",
       "2  [### Model Architecture\\n\\nOur config also def...   \n",
       "3  [ # A 3-in-1 Intro to Weights & Biases: Comput...   \n",
       "4  [## Basic Example\\n\\nThe W&B SB3 integration u...   \n",
       "\n",
       "                             retrieved_context_stuff  tokens  \n",
       "0  `wandb.init()` returns a run object, and you c...   15505  \n",
       "1  ### How do I best log models from runs in a sw...   13161  \n",
       "2  ### Model Architecture\\n\\nOur config also defi...   17812  \n",
       "3   # A 3-in-1 Intro to Weights & Biases: Compute...   12755  \n",
       "4  ## Basic Example\\n\\nThe W&B SB3 integration us...   15480  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24f78893-9828-4c35-b5e6-a84b5a32134b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df = eval_df[[\"query\", \"generated_response\", \"retrieved_context_stuff\", \"tokens\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "70e8f2c5-1c1a-4cc7-9419-bf2e8749cb9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df.columns = [\"question\", \"answer\", \"retrieved_context\", \"char_len\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "50e7ff7d-27fe-4e9d-b04a-98a9494387c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>page_content</th>\n",
       "      <th>char_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey I have a question about using wandb with f...</td>\n",
       "      <td>The initialization of `wandb.init()` should be...</td>\n",
       "      <td>`wandb.init()` returns a run object, and you c...</td>\n",
       "      <td>15505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey with wandb is it possible to link from the...</td>\n",
       "      <td>Yes, you can link to the best run from a sweep...</td>\n",
       "      <td>### How do I best log models from runs in a sw...</td>\n",
       "      <td>13161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am training a spacy textcat model. This proc...</td>\n",
       "      <td>To log the best model's metrics instead of the...</td>\n",
       "      <td>### Model Architecture\\n\\nOur config also defi...</td>\n",
       "      <td>17812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explain how I can version datasets with Weight...</td>\n",
       "      <td>Weights &amp; Biases provides a feature called Art...</td>\n",
       "      <td># A 3-in-1 Intro to Weights &amp; Biases: Compute...</td>\n",
       "      <td>12755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm using   env = SubprocVecEnv(\\n        [mak...</td>\n",
       "      <td>To record a video for a specific subprocess en...</td>\n",
       "      <td>## Basic Example\\n\\nThe W&amp;B SB3 integration us...</td>\n",
       "      <td>15480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Hey I have a question about using wandb with f...   \n",
       "1  Hey with wandb is it possible to link from the...   \n",
       "2  I am training a spacy textcat model. This proc...   \n",
       "3  Explain how I can version datasets with Weight...   \n",
       "4  I'm using   env = SubprocVecEnv(\\n        [mak...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The initialization of `wandb.init()` should be...   \n",
       "1  Yes, you can link to the best run from a sweep...   \n",
       "2  To log the best model's metrics instead of the...   \n",
       "3  Weights & Biases provides a feature called Art...   \n",
       "4  To record a video for a specific subprocess en...   \n",
       "\n",
       "                                        page_content  char_len  \n",
       "0  `wandb.init()` returns a run object, and you c...     15505  \n",
       "1  ### How do I best log models from runs in a sw...     13161  \n",
       "2  ### Model Architecture\\n\\nOur config also defi...     17812  \n",
       "3   # A 3-in-1 Intro to Weights & Biases: Compute...     12755  \n",
       "4  ## Basic Example\\n\\nThe W&B SB3 integration us...     15480  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = eval_df.rename({\"retrieved_context\": \"page_content\"}, axis=1)\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f8de07-59c4-40f0-810b-7a1805ab5a8a",
   "metadata": {},
   "source": [
    "## Save to W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108ce808-876b-404d-bc98-eba585672252",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's format the dataset in the same way we created the training dataset, we have to be consisten with naming\n",
    "- We remove the answer, but we are going to keep it on the dataset to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "664f5165-0d3d-4e19-b237-2d9c198c5c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "B_INST, E_INST = \"[INST] \", \" [/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "EOS = \"</s>\"\n",
    "\n",
    "eval_prompt_format = (\n",
    "    B_INST\n",
    "    + B_SYS\n",
    "    + \"You are an AI assistant designed to assist developers with everyday tasks related to Weight & Biases \"\n",
    "    + \"and provide helpful information. As an expert in the open-source python SDK wandb answer the following \"\n",
    "    # + \"question based on the context below. Answer in formatted Markdown.\\n\"\n",
    "    + \"question below. Answer in formatted Markdown.\\n\"\n",
    "    + \"{page_content}\"\n",
    "    + E_SYS\n",
    "    + \"{question}\"\n",
    "    + E_INST\n",
    "    + \"\\n[W&B]\\n\"\n",
    "    # + \"{answer}\"\n",
    "    # + \"\\n[/W&B]\"\n",
    "    # + EOS\n",
    ")\n",
    "\n",
    "def eval_format_text(row):\n",
    "    return eval_prompt_format.format_map(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb560592-dbef-4da7-a9cb-a3463341910c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df[\"text\"] = eval_df.apply(eval_format_text, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29f448b-07a4-4dc9-8621-98d50a9edcd0",
   "metadata": {},
   "source": [
    "Save to disk and create HF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2b6c968a-892d-4d76-a921-63a473bc71dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2349fd8fcad843059ca2a466fb3c63dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295412ff77f449abbe0a3e4d35f1bfb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2943f42a5c5c47f19522e4f88de68ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'page_content', 'char_len', 'text'],\n",
       "        num_rows: 132\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.to_json(\"wandbot_eval.jsonl\", orient='records', lines=True)\n",
    "eval_dataset = load_dataset(\".\", data_files=\"wandbot_eval.jsonl\")\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3dd86384-2cae-41f8-83a5-6597242244db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_input_path = \"./wandbot_eval_ds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a4c5caf-c577-4360-881d-ef36b5bb39d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d417aa3db7c4600b01b3b2caff55e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/132 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dataset.save_to_disk(eval_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd9a87e0-d691-4076-8894-c5f4157bdf7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 105942 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 110242 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 182827 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 193712 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 120537 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 124957 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 100379 bytes\n"
     ]
    }
   ],
   "source": [
    "table = wandb.Table(dataframe=eval_df)\n",
    "wandb.log({\"wandbot_eval_dataset\": table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4d615bb7-f385-4771-a593-c2845561d0fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "at = wandb.Artifact(\n",
    "    name=\"wandbot_eval_dataset\", \n",
    "    type=\"dataset\",\n",
    "    description=\"A wandbot dataset of questions and answers about W&B for evaluation\",\n",
    "    metadata={\"prompt_format\": eval_prompt_format,\n",
    "              \"length\": len(eval_dataset),\n",
    "             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b87fb8c-c12e-4f63-b9d2-6ef7d014db1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./wandbot_eval_ds)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Artifact wandbot_eval_dataset>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at.add_dir(eval_input_path)\n",
    "wandb.log_artifact(at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab877b6f-28e2-4d2d-bf28-86cba3736dcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abcab447e35743cfb4dcecbe83984bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='12.082 MB of 12.082 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, mâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dulcet-rain-9</strong> at: <a href='https://wandb.ai/capecape/wandbot_llm/runs/owx86rej' target=\"_blank\">https://wandb.ai/capecape/wandbot_llm/runs/owx86rej</a><br/>Synced 5 W&B file(s), 1 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231018_122100-owx86rej/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
